---
phase: 01-foundation
plan: 03
type: execute
wave: 3
depends_on: ["01-02"]
files_modified:
  - tests/conftest.py
  - tests/test_portfolio.py
  - tests/test_validation.py
  - tests/test_quality.py
  - tests/fixtures/valid_portfolio.csv
  - tests/fixtures/valid_portfolio.xlsx
  - tests/fixtures/invalid_missing_field.csv
  - tests/fixtures/invalid_future_date.csv
  - tests/fixtures/invalid_duplicate_id.csv
autonomous: true

must_haves:
  truths:
    - "All tests pass with pytest"
    - "Tests cover loading from CSV and Excel"
    - "Tests cover validation failures (missing fields, future dates, duplicate IDs)"
    - "Tests cover quality metrics computation"
    - "Tests cover portfolio querying and filtering"
  artifacts:
    - path: "tests/conftest.py"
      provides: "Shared test fixtures"
      min_lines: 20
    - path: "tests/test_portfolio.py"
      provides: "Portfolio loading and query tests"
      min_lines: 80
    - path: "tests/test_validation.py"
      provides: "Validation failure tests"
      min_lines: 40
    - path: "tests/test_quality.py"
      provides: "Quality metrics tests"
      min_lines: 30
    - path: "tests/fixtures/valid_portfolio.csv"
      provides: "Sample valid portfolio data"
  key_links:
    - from: "tests/test_portfolio.py"
      to: "src/asset_optimization/portfolio.py"
      via: "import Portfolio"
      pattern: "from asset_optimization import Portfolio"
    - from: "tests/test_validation.py"
      to: "src/asset_optimization/exceptions.py"
      via: "import exceptions"
      pattern: "from asset_optimization import ValidationError"
---

<objective>
Create comprehensive test suite for Portfolio loading, validation, quality metrics, and querying.

Purpose: Verify all Phase 1 requirements are met and provide regression safety for future phases.

Output: Passing test suite covering all Portfolio functionality.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test fixtures</name>
  <files>
    tests/fixtures/valid_portfolio.csv
    tests/fixtures/valid_portfolio.xlsx
    tests/fixtures/invalid_missing_field.csv
    tests/fixtures/invalid_future_date.csv
    tests/fixtures/invalid_duplicate_id.csv
    tests/conftest.py
  </files>
  <action>
Create test fixture files:

1. `tests/fixtures/valid_portfolio.csv` with 10+ rows:
   - All required fields: asset_id, install_date, asset_type, material
   - Optional fields: diameter_mm, length_m, condition_score
   - Mix of asset types (pipe, valve)
   - Various install dates (2010-2023)
   - Some nullable fields with missing values (to test quality metrics)

2. `tests/fixtures/valid_portfolio.xlsx`:
   - Same data as CSV but in Excel format
   - Use openpyxl to create (or pandas to_excel)

3. `tests/fixtures/invalid_missing_field.csv`:
   - Missing the `asset_id` column entirely

4. `tests/fixtures/invalid_future_date.csv`:
   - Has install_date in 2030 (future)

5. `tests/fixtures/invalid_duplicate_id.csv`:
   - Has two rows with same asset_id

6. `tests/conftest.py` with pytest fixtures:
   - `valid_csv_path` — path to valid_portfolio.csv
   - `valid_excel_path` — path to valid_portfolio.xlsx
   - `invalid_missing_field_path` — path to invalid_missing_field.csv
   - `invalid_future_date_path` — path to invalid_future_date.csv
   - `invalid_duplicate_id_path` — path to invalid_duplicate_id.csv
   - `sample_dataframe` — in-memory valid DataFrame

Use pathlib.Path for all file paths. Fixtures should use `@pytest.fixture` decorator.
  </action>
  <verify>
Run: `uv run python -c "import pandas as pd; df = pd.read_csv('tests/fixtures/valid_portfolio.csv'); print(f'Rows: {len(df)}, Columns: {list(df.columns)}')"`
Expected: Shows 10+ rows with required columns.
  </verify>
  <done>Test fixtures exist for valid and invalid portfolio data; conftest.py provides fixtures to tests.</done>
</task>

<task type="auto">
  <name>Task 2: Create test suite</name>
  <files>
    tests/test_portfolio.py
    tests/test_validation.py
    tests/test_quality.py
  </files>
  <action>
Create test files:

**tests/test_portfolio.py:**
1. `test_load_from_csv` — loads valid CSV, checks n_assets > 0
2. `test_load_from_excel` — loads valid Excel, checks n_assets > 0
3. `test_load_from_dataframe` — loads in-memory DataFrame
4. `test_len_returns_asset_count` — len(portfolio) matches row count
5. `test_getitem_returns_asset` — portfolio['PIPE-001'] returns Series
6. `test_getitem_missing_raises_keyerror` — portfolio['NONEXISTENT'] raises KeyError
7. `test_repr_is_informative` — repr contains 'Portfolio', asset count, types
8. `test_data_property_returns_dataframe` — portfolio.data is DataFrame
9. `test_asset_types_property` — returns list of unique types
10. `test_mean_age_property` — returns float > 0
11. `test_age_distribution_property` — returns Series with same length as portfolio
12. `test_oldest_property` — returns Series with oldest asset
13. `test_newest_property` — returns Series with newest asset

**tests/test_validation.py:**
1. `test_missing_required_field_raises_validation_error` — missing asset_id column
2. `test_future_date_raises_validation_error` — install_date in future
3. `test_duplicate_id_raises_validation_error` — duplicate asset_id values
4. `test_validation_error_has_field_attribute` — error.field is set
5. `test_validation_error_has_message_attribute` — error.message is set
6. `test_validation_error_has_details_attribute` — error.details is dict

**tests/test_quality.py:**
1. `test_quality_property_returns_metrics` — portfolio.quality is QualityMetrics
2. `test_completeness_is_series` — quality.completeness is pd.Series
3. `test_missing_counts_is_series` — quality.missing_counts is pd.Series
4. `test_total_rows_matches_len` — quality.total_rows == len(portfolio)
5. `test_completeness_values_between_0_and_1` — all values in [0, 1]
6. `test_quality_repr_not_empty` — repr(quality) is non-empty string
7. `test_quality_repr_html_for_notebook` — _repr_html_() returns HTML string

Use pytest.raises for exception tests. Use descriptive assertion messages.
  </action>
  <verify>
Run: `uv run pytest tests/ -v`
Expected: All tests pass (26+ tests).
  </verify>
  <done>Test suite passes; all Portfolio loading, validation, quality, and query functionality is tested.</done>
</task>

</tasks>

<verification>
After both tasks complete:
1. `uv run pytest tests/` shows all tests passing
2. Tests cover: CSV loading, Excel loading, DataFrame loading
3. Tests cover: validation errors for missing fields, future dates, duplicate IDs
4. Tests cover: quality metrics computation and display
5. Tests cover: portfolio querying (dict access, properties, len, repr)
6. No test failures or errors
</verification>

<success_criteria>
- All tests pass with `uv run pytest tests/ -v`
- Test coverage includes happy paths and error cases
- Fixtures provide reusable test data
- Tests are descriptive and maintainable
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md`
</output>
